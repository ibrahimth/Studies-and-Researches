import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras import regularizers
#from keras.optimizers import SGD

# Generate dummy data
import numpy as np
signal_reward = [
    ([0, 0, 0, 0.9830496735786511, -0.9830496735786511], -0.2), 
    ([0, 0, 0, -0.9046591494269619, 0.9046591494269619], -0.2), 
    ([0, 0, 0, 0.8721487936783692, -0.8721487936783692], -0.2), 
    ([0, 0, 0, 0.7625643804703914, -0.7625643804703914], -0.2), 
    ([0, 0, 0, 0.6540797799487251, -0.6540797799487251], -0.2), 
    ([0, 0, 0, 0.5463747856674654, -0.5463747856674654], -0.2), 
    ([0, 0, 0, 0.43906420304292, -0.43906420304292], -0.2), 
    ([0, 0, 0, 0.3317325547615686, -0.3317325547615686], 0.1), 
    ([0, 0, 0, 0.22396593739574758, -0.22396593739574758], 0.1), 
    ([0, 0, 0, 0.1153840440311003, -0.1153840440311003], 0.1), 
    ([0, 0, 0, 0.005675263431393714, -0.005675263431393714], 0.1), 
    ([0, 0, 0, -0.1053644559775644, 0.1053644559775644], 0.1), 
    ([0, 0, 0, -0.21779265326409813, 0.21779265326409813], 0.1), 
    ([0, 0, 0, -0.3314907110330212, 0.3314907110330212], 0.1), 
    ([0, 0, 0, -0.4461573261115725, 0.4461573261115725], 0.1), 
    ([0, 0, 0, -0.561337583365171, 0.561337583365171], 0.1), 
    ([0, 0, 0, -0.6764899863533059, 0.6764899863533059], -0.2), 
    ([0, 0, 0, -0.7910778257922126, 0.7910778257922126], -0.2), 
    ([0, 0, 0, -0.904659149426962, 0.904659149426962], -0.2), 
    ([0, 0, 0, 0.9830496735786511, -0.9830496735786511], -0.2), 
    ([0, 0, 0, 0.8721487936783691, -0.8721487936783691], -0.2), 
    ([0, 0, 0, 0.7625643804703914, -0.7625643804703914], -0.2), 
    ([0, 0, 0, 0.6540797799487252, -0.6540797799487252], -0.2), 
    ([0, 0, 0, 0.5463747856674658, -0.5463747856674658], -0.2), 
    ([0, 0, 0, 0.43906420304291977, -0.43906420304291977], -0.2), 
    ([0, 0, 0, 0.33173255476156854, -0.33173255476156854], 0.1), 
    ([0, 0, 0, 0.2239659373957477, -0.2239659373957477], 0.1), 
    ([0, 0, 0, 0.11538404403110054, -0.11538404403110054], 0.1), 
    ([0, 0, 0, 0.0056752634313934885, -0.0056752634313934885], 0.1), 
    ([0, 0, 0, -0.10536445597756458, 0.10536445597756458], 0.1), 
    ([0, 0, 0, -0.21779265326409805, 0.21779265326409805], 0.1), 
    ([0, 0, 0, -0.3314907110330211, 0.3314907110330211], 0.1), 
    ([0, 0, 0, -0.4461573261115721, 0.4461573261115721], 0.1), 
    ([0, 0, 0, -0.5613375833651713, 0.5613375833651713], 0.1), 
    ([0, 0, 0, -0.6764899863533057, 0.6764899863533057], -0.2), 
    ([0, 0, 0, -0.7910778257922124, 0.7910778257922124], -0.2), 
    ([0, 0, 0, -0.9046591494269616, 0.9046591494269616], -0.2), 
    ([0, 0, 0, 0.9830496735786509, -0.9830496735786509], -0.2), 
    ([0, 0, 0, 0.8721487936783691, -0.8721487936783691], -0.2), 
    ([0, 0, 0, 0.7625643804703914, -0.7625643804703914], -0.2), 
    ([0, 0, 0, 0.6540797799487252, -0.6540797799487252], -0.2), 
    ([0, 0, 0, 0.5463747856674653, -0.5463747856674653], -0.2), 
    ([0, 0, 0, 0.43906420304291977, -0.43906420304291977], -0.2), 
    ([0, 0, 0, 0.3317325547615686, -0.3317325547615686], 0.1), 
    ([0, 0, 0, 0.22396593739574777, -0.22396593739574777], 0.1), 
    ([0, 0, 0, 0.11538404403110061, -0.11538404403110061], 0.1), 
    ([0, 0, 0, 0.005675263431394137, -0.005675263431394137], 0.1), 
    ([0, 0, 0, -0.10536445597756396, 0.10536445597756396], 0.1), 
    ([0, 0, 0, -0.21779265326409852, 0.21779265326409852], 0.1), 
    ([0, 0, 0, -0.33149071103302163, 0.33149071103302163], 0.1), 
    ([0, 0, 0, -0.44615732611157255, 0.44615732611157255], 0.1), 
    ([0, 0, 0, -0.5613375833651713, 0.5613375833651713], 0.1), 
    ([0, 0, 0, -0.6764899863533057, 0.6764899863533057], -0.2), 
    ([0, 0, 0, -0.7910778257922124, 0.7910778257922124], -0.2), 
    ([0, 0, 0, -0.9046591494269616, 0.9046591494269616], -0.2), 
    ([0, 0, 0, 0.9830496735786516, -0.9830496735786516], -0.2), 
    ([0, 0, 0, 0.8721487936783696, -0.8721487936783696], -0.2), 
    ([0, 0, 0, 0.762564380470391, -0.762564380470391], -0.2), 
    ([0, 0, 0, 0.6540797799487249, -0.6540797799487249], -0.2), 
    ([0, 0, 0, 0.5463747856674654, -0.5463747856674654], -0.2), 
    ([0, 0, 0, 0.43906420304291993, -0.43906420304291993], -0.2), 
    ([0, 0, 0, 0.33173255476156865, -0.33173255476156865], 0.1), 
    ([0, 0, 0, 0.22396593739574785, -0.22396593739574785], 0.1), 
    ([0, 0, 0, 0.11538404403110068, -0.11538404403110068], 0.1), 
    ([0, 0, 0, 0.005675263431394237, -0.005675263431394237], 0.1), 
    ([0, 0, 0, -0.1053644559775639, 0.1053644559775639], 0.1), 
    ([0, 0, 0, -0.2177926532640985, 0.2177926532640985], 0.1), 
    ([0, 0, 0, -0.3314907110330215, 0.3314907110330215], 0.1), 
    ([0, 0, 0, -0.4461573261115725, 0.4461573261115725], 0.1), 
    ([0, 0, 0, -0.561337583365171, 0.561337583365171], 0.1), 
    ([0, 0, 0, -0.6764899863533057, 0.6764899863533057], -0.2), 
    ([0, 0, 0, -0.7910778257922123, 0.7910778257922123], -0.2), 
    ([0, 0, 0, -0.9046591494269614, 0.9046591494269614], -0.2), 
    ([0, 0, 0, 0.9830496735786517, -0.9830496735786517], -0.2), 
    ([0, 0, 0, 0.8721487936783698, -0.8721487936783698], -0.2), 
    ([0, 0, 0, 0.762564380470391, -0.762564380470391], -0.2), 
    ([0, 0, 0, 0.654079779948725, -0.654079779948725], -0.2), 
    ([0, 0, 0, 0.5463747856674654, -0.5463747856674654], -0.2), 
    ([0, 0, 0, 0.43906420304292, -0.43906420304292], -0.2), 
    ([0, 0, 0, 0.33173255476156877, -0.33173255476156877], 0.1), 
    ([0, 0, 0, 0.22396593739574788, -0.22396593739574788], 0.1), 
    ([0, 0, 0, 0.11538404403110077, -0.11538404403110077], 0.1), 
    ([0, 0, 0, 0.0056752634313943385, -0.0056752634313943385], 0.1), 
    ([0, 0, 0, -0.10536445597756493, 0.10536445597756493], 0.1), 
    ([0, 0, 0, -0.21779265326409838, 0.21779265326409838], 0.1), 
    ([0, 0, 0, -0.33149071103302147, 0.33149071103302147], 0.1), 
    ([0, 0, 0, -0.44615732611157244, 0.44615732611157244], 0.1), 
    ([0, 0, 0, -0.561337583365171, 0.561337583365171], 0.1), 
    ([0, 0, 0, -0.6764899863533057, 0.6764899863533057], -0.2), 
    ([0, 0, 0, -0.7910778257922123, 0.7910778257922123], -0.2), 
    ([0, 0, 0, -0.9046591494269614, 0.9046591494269614], -0.2), 
    ([0, 0, 0, 0.9830496735786517, -0.9830496735786517], -0.2), 
    ([0, 0, 0, 0.8721487936783698, -0.8721487936783698], -0.2), 
    ([0, 0, 0, 0.7625643804703923, -0.7625643804703923], -0.2), 
    ([0, 0, 0, 0.6540797799487261, -0.6540797799487261], -0.2), 
    ([0, 0, 0, 0.5463747856674667, -0.5463747856674667], -0.2), 
    ([0, 0, 0, 0.4390642030429212, -0.4390642030429212], -0.2), 
    ([0, 0, 0, 0.33173255476156766, -0.33173255476156766], 0.1), 
    ([0, 0, 0, 0.22396593739574683, -0.22396593739574683], 0.1), 
    ([0, 0, 0, 0.11538404403109968, -0.11538404403109968], 0.1)]

model = Sequential()
model.add(Dense(30, 
    kernel_regularizer = regularizers.l2(0.01),
    activity_regularizer = regularizers.l1(0.01),    
    activation = 'relu', input_dim = 5))
model.add(Dense(3, activation = 'softmax'))

#sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)
#model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])

#THIS IS HOW TO USE L2 IN KERAS => add to the hidden layer and use this loss='mean_squared_error'
#model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

#monitor = EarlyStopping(monitor='val_loss', min_deta=le-3, patience = 5, verbose = 1, mode = 'auto')
#model.fit(x, y, validation_data=(x_text, y_text), callbacks=[monitor], verbose=0, epochs=1000)
#pred = model.predict(x_test)
#score = np.sqrt(metrics.mean_squared_error(pred, y_test))
#print("Final score (RMSE): {}".format(score))

x_train = []
y_train = []

#FOR EACH SIGNAL
#GET REWARD FOR THE CURRENT SIGNAL
#GET REWARD FOR THE NEXT SIGNAL
#X_TRAIN = (STATE, TARGET)
#TARGET = (OUTPUT_STATE * GAMMA + REWARD_LAST_STATE)
gamma = 0.9
for i in range(len(signal_reward) - 1):
    signal_reshape = np.reshape(signal_reward[i][0], (1, 5))
    output_state = model.predict(signal_reshape)
    action = np.argmax(output_state[0])
    output_state[0][action] = output_state[0][action] * gamma + signal_reward[i][1]        

    x_train.append(signal_reward[i][0])
    y_target = [0., 0., 0.]
    target_action = np.argmax(output_state)
    y_target[target_action] = 1
    y_train.append(y_target)
    
# for i in range(len(x_train)):
#     print(x_train[i], y_train[i])

# print(x_train, y_train)

model.fit(np.array(x_train), np.array(y_train))

x_test = [
    [0, 0, 0, -0.9046591494269614, 0.9046591494269614], 
    [0, 0, 0, 0.9830496735786517, -0.9830496735786517], 
    [0, 0, 0, 0.8721487936783698, -0.8721487936783698], 
    [0, 0, 0, 0.7625643804703923, -0.7625643804703923], 
    [0, 0, 0, 0.6540797799487261, -0.6540797799487261], 
    [0, 0, 0, 0.5463747856674667, -0.5463747856674667]]

y_pred = model.predict(np.array(x_test))
print(y_pred)

#score = model.evaluate(x_test, y_test, batch_size = 128)
#print(score)